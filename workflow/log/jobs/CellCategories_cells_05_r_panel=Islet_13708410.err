Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Select jobs to execute...

[Fri Mar 22 10:52:21 2024]
rule CellCategories_cells_05_r:
    input: /home/nsteen/scripts/T1D_analysis/analysis/05_CellCategories_cells_Islet.Rmd, /home/nsteen/scripts/T1D_analysis/docs/04_QualityControl_cells_Islet.html
    output: /home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Islet.html
    jobid: 0
    benchmark: /home/nsteen/scripts/T1D_analysis/benchmark/05_CellCategories_cells_Islet.txt
    reason: Forced execution
    wildcards: panel=Islet
    threads: 8
    resources: mem_mb=350000, disk_mb=1000, tmpdir=/sctmp/nsteen, time=24:00:00

Rscript --vanilla -e 'rmarkdown::render("/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmp026a5osz.05_CellCategories_cells_Islet.Rmd", output_file="/home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Islet.html", quiet=TRUE, knit_root_dir = "/home/nsteen/scripts/T1D_analysis", params = list(rmd="/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmp026a5osz.05_CellCategories_cells_Islet.Rmd"))'
Activating singularity image /home/nsteen/data/singularity/sandbox/
 - point 10000 of 90980
 - point 20000 of 90980
 - point 30000 of 90980
 - point 40000 of 90980
 - point 50000 of 90980
 - point 60000 of 90980
 - point 70000 of 90980
 - point 80000 of 90980
 - point 90000 of 90980
 - point 10000 of 90980
 - point 20000 of 90980
 - point 30000 of 90980
 - point 40000 of 90980
 - point 50000 of 90980
 - point 60000 of 90980
 - point 70000 of 90980
 - point 80000 of 90980
 - point 90000 of 90980
 - point 10000 of 90980
 - point 20000 of 90980
 - point 30000 of 90980
 - point 40000 of 90980
 - point 50000 of 90980
 - point 60000 of 90980
 - point 70000 of 90980
 - point 80000 of 90980
 - point 90000 of 90980

Quitting from lines 1106-1164 [celltypes-pheno-scaled] (/sctmp/nsteen/RtmpYxeEAi/tmp026a5osz.05_CellCategories_cells_Islet.Rmd)
Error:
! Recheck cluster attribution
Execution halted
Not cleaning up /home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmp026a5osz.05_CellCategories_cells_Islet.Rmd
[Fri Mar 22 12:17:21 2024]
Error in rule CellCategories_cells_05_r:
    jobid: 0
    output: /home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Islet.html

RuleException:
CalledProcessError in line 123 of /home/nsteen/scripts/T1D_analysis/workflow/Snakefile:
Command ' singularity  exec --home /home/nsteen/scripts/T1D_analysis --bind /home/nsteen/scripts/T1D_analysis:/home/nsteen/scripts/T1D_analysis,/scratch/nsteen/processing:/home/processing,/scratch/nsteen/T1D_preprocessing:/scratch/nsteen/T1D_preprocessing,/data/nsteen:/data/nsteen /home/nsteen/data/singularity/sandbox/ bash -c 'set -euo pipefail;  Rscript --vanilla -e '\''rmarkdown::render("/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmp026a5osz.05_CellCategories_cells_Islet.Rmd", output_file="/home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Islet.html", quiet=TRUE, knit_root_dir = "/home/nsteen/scripts/T1D_analysis", params = list(rmd="/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmp026a5osz.05_CellCategories_cells_Islet.Rmd"))'\'''' returned non-zero exit status 1.
  File "/home/nsteen/scripts/T1D_analysis/workflow/Snakefile", line 123, in __rule_CellCategories_cells_05_r
  File "/home/nsteen/data/conda/envs/snakemake_cluster/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
