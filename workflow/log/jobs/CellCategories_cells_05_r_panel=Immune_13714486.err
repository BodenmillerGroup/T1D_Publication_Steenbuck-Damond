Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Select jobs to execute...

[Fri Mar 22 19:12:48 2024]
rule CellCategories_cells_05_r:
    input: /home/nsteen/scripts/T1D_analysis/analysis/05_CellCategories_cells_Immune.Rmd, /home/nsteen/scripts/T1D_analysis/docs/04_QualityControl_cells_Immune.html
    output: /home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Immune.html
    jobid: 0
    benchmark: /home/nsteen/scripts/T1D_analysis/benchmark/05_CellCategories_cells_Immune.txt
    reason: Forced execution
    wildcards: panel=Immune
    threads: 8
    resources: mem_mb=350000, disk_mb=1000, tmpdir=/sctmp/nsteen, time=24:00:00

Rscript --vanilla -e 'rmarkdown::render("/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmpcxn3vkv6.05_CellCategories_cells_Immune.Rmd", output_file="/home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Immune.html", quiet=TRUE, knit_root_dir = "/home/nsteen/scripts/T1D_analysis", params = list(rmd="/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmpcxn3vkv6.05_CellCategories_cells_Immune.Rmd"))'
Activating singularity image /home/nsteen/data/singularity/sandbox/
 - point 10000 of 190000
 - point 20000 of 190000
 - point 30000 of 190000
 - point 40000 of 190000
 - point 50000 of 190000
 - point 60000 of 190000
 - point 70000 of 190000
 - point 80000 of 190000
 - point 90000 of 190000
 - point 100000 of 190000
 - point 110000 of 190000
 - point 120000 of 190000
 - point 130000 of 190000
 - point 140000 of 190000
 - point 150000 of 190000
 - point 160000 of 190000
 - point 170000 of 190000
 - point 180000 of 190000
 - point 190000 of 190000
 - point 10000 of 190000
 - point 20000 of 190000
 - point 30000 of 190000
 - point 40000 of 190000
 - point 50000 of 190000
 - point 60000 of 190000
 - point 70000 of 190000
 - point 80000 of 190000
 - point 90000 of 190000
 - point 100000 of 190000
 - point 110000 of 190000
 - point 120000 of 190000
 - point 130000 of 190000
 - point 140000 of 190000
 - point 150000 of 190000
 - point 160001 of 190000
 - point 170000 of 190000
 - point 180000 of 190000
 - point 190000 of 190000
 - point 10000 of 190000
 - point 20001 of 190000
 - point 30000 of 190000
 - point 40000 of 190000
 - point 50000 of 190000
 - point 60000 of 190000
 - point 70000 of 190000
 - point 80000 of 190000
 - point 90000 of 190000
 - point 100001 of 190000
 - point 110000 of 190000
 - point 120000 of 190000
 - point 130000 of 190000
 - point 140000 of 190000
 - point 150000 of 190000
 - point 160000 of 190000
 - point 170000 of 190000
 - point 180000 of 190000
 - point 190000 of 190000

Quitting from lines 1173-1186 [viz-cluster-cytoviewer] (/sctmp/nsteen/RtmpcMeMLg/tmpcxn3vkv6.05_CellCategories_cells_Immune.Rmd)
Error in `library()`:
! there is no package called 'cytoviewer'
Backtrace:
 1. base::library(cytoviewer)
Execution halted
Not cleaning up /home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmpcxn3vkv6.05_CellCategories_cells_Immune.Rmd
[Sat Mar 23 11:16:00 2024]
Error in rule CellCategories_cells_05_r:
    jobid: 0
    output: /home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Immune.html

RuleException:
CalledProcessError in line 123 of /home/nsteen/scripts/T1D_analysis/workflow/Snakefile:
Command ' singularity  exec --home /home/nsteen/scripts/T1D_analysis --bind /home/nsteen/scripts/T1D_analysis:/home/nsteen/scripts/T1D_analysis,/scratch/nsteen/processing:/home/processing,/scratch/nsteen/T1D_preprocessing:/scratch/nsteen/T1D_preprocessing,/data/nsteen:/data/nsteen /home/nsteen/data/singularity/sandbox/ bash -c 'set -euo pipefail;  Rscript --vanilla -e '\''rmarkdown::render("/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmpcxn3vkv6.05_CellCategories_cells_Immune.Rmd", output_file="/home/nsteen/scripts/T1D_analysis/docs/05_CellCategories_cells_Immune.html", quiet=TRUE, knit_root_dir = "/home/nsteen/scripts/T1D_analysis", params = list(rmd="/home/nsteen/scripts/T1D_analysis/.snakemake/scripts/tmpcxn3vkv6.05_CellCategories_cells_Immune.Rmd"))'\'''' returned non-zero exit status 1.
  File "/home/nsteen/scripts/T1D_analysis/workflow/Snakefile", line 123, in __rule_CellCategories_cells_05_r
  File "/home/nsteen/data/conda/envs/snakemake_cluster/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
