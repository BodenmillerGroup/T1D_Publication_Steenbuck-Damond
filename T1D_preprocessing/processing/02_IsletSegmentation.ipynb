{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34973ddf",
   "metadata": {},
   "source": [
    "# **Islet segmentation**\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "This is the second script in the processing pipeline for IMC data.\n",
    "\n",
    "The goal of this script is to identify and label islets. This is done using a UNET-based deep learning segmentation model (see the `islet_segmentation` folder in this repository for details and model training).\n",
    "\n",
    "**Main steps:**\n",
    "\n",
    "*1. Generate segmentation images:* Channels corresponding to islet-specific marker(s) are subset to generate single-channel images that are used as the input to the model.\n",
    "\n",
    "*2. Segment islets:* The U-NET model is loaded and used to predict islet masks from segmentation images.\n",
    "\n",
    "*3. Match and relabel islets on consecutive sections:* If the same islet is present on two consecutive sections, the same label is assigned to it on the corresponding masks. Islets located close to **each other in an image are merged.\n",
    "\n",
    "*4. Quality check:* Images and masks from consecutive sections are displayed side-by-side for visual verification of the quality of the segmentation. Problematic images are flagged for deletion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762912fa",
   "metadata": {},
   "source": [
    "## **Configuration**\n",
    "\n",
    "### **Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a98f287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce7d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from cv2 import legacy\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from random import sample\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from skimage import measure, color, exposure\n",
    "from skimage.registration import optical_flow_tvl1\n",
    "from skimage.segmentation import expand_labels, mark_boundaries\n",
    "from skimage.transform import warp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8245b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steinbock import io\n",
    "from steinbock.segmentation import deepcell\n",
    "\n",
    "sys.path.append(\"../islet_segmentation\") \n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af14a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/T1D_preprocessing/processing', '/opt/conda/lib/python39.zip', '/opt/conda/lib/python3.9', '/opt/conda/lib/python3.9/lib-dynload', '', '/opt/conda/lib/python3.9/site-packages', '../islet_segmentation']\n",
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa3ef3a",
   "metadata": {},
   "source": [
    "### **Load directories and panels**\n",
    "\n",
    "Paths to input and output folders as well as antibody panels were exported by the first script (`01_Preprocessing.ipynb`). Here they are imported again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76803dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52967eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': PosixPath('/home/processing/raw'),\n",
       " 'img': PosixPath('/home/processing/img'),\n",
       " 'seg_cells': PosixPath('/home/processing/seg_cells'),\n",
       " 'seg_islets': PosixPath('/home/processing/seg_islets'),\n",
       " 'masks_cells': PosixPath('/home/processing/masks_cells'),\n",
       " 'masks_islets': PosixPath('/home/processing/masks_islets'),\n",
       " 'data_cells': PosixPath('/home/processing/data_cells'),\n",
       " 'data_islets': PosixPath('/home/processing/data_islets'),\n",
       " 'variables': PosixPath('/home/processing/variables'),\n",
       " 'data': PosixPath('/home/processing'),\n",
       " 'git': PosixPath('/home/processing')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./variables/folders.txt\", \"rb\") as handle:\n",
    "    folders = pickle.loads(handle.read())\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dca1fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Islet \n",
      "    channel  metal          name antibody_clone  keep  isletseg  deepcell  \\\n",
      "0        0    Y89       Ghrelin         883622     1       NaN       NaN   \n",
      "1        1  In113   Histone H3            D1H2     1       NaN       1.0   \n",
      "2        2  In115        Biotin         1D4-C5     1       NaN       NaN   \n",
      "6        6  La139  Somatostatin         ICDCLS     1       NaN       NaN   \n",
      "7        7  Ce140       Insulin        19H4L12     1       NaN       NaN   \n",
      "\n",
      "   dimred  clustering short_name  \n",
      "0     1.0         1.0       GHRL  \n",
      "1     0.0         0.0         H3  \n",
      "2     1.0         0.0        HBP  \n",
      "6     1.0         1.0        SST  \n",
      "7     1.0         1.0        INS  \n",
      "Immune \n",
      "    channel  metal          name antibody_clone  keep  isletseg  deepcell  \\\n",
      "0        0    Y89           MPO            pAb     1       NaN       NaN   \n",
      "1        1  In113   Histone H3            D1H2     1       NaN       1.0   \n",
      "2        2  In115           SMA            1A4     1       NaN       NaN   \n",
      "6        6  La139  Somatostatin         ICDCLS     1       NaN       NaN   \n",
      "7        7  Ce140       Insulin        19H4L12     1       NaN       NaN   \n",
      "\n",
      "   dimred  clustering short_name  \n",
      "0       1           1        MPO  \n",
      "1       0           0         H3  \n",
      "2       1           1        SMA  \n",
      "6       1           1        SST  \n",
      "7       1           1        INS  \n"
     ]
    }
   ],
   "source": [
    "with open(\"./variables/panels.txt\", \"rb\") as handle:\n",
    "    panels = pickle.loads(handle.read())\n",
    "\n",
    "for panel_name, panel in panels.items():\n",
    "    print(panel_name, \"\\n\", panel.head())\n",
    "panel_names = list(panels.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d3e09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Generate segmentation images**\n",
    "\n",
    "### **Settings**\n",
    "Segmentation stacks are generated by aggregating the channels selected in the `panel.csv` files (value = 1 in the column `isletseg`).  \n",
    "Different functions can be used to aggregate channels. Default: `np.mean`, for other options, see https://numpy.org/doc/stable/reference/routines.statistics.html#averages-and-variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab36a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define image preprocessing options\n",
    "channelwise_zscore = False\n",
    "channelwise_minmax = True\n",
    "aggr_func = np.mean\n",
    "\n",
    "# Initialize image data frames to store image metadata\n",
    "image_dfs = dict.fromkeys(panel_names)\n",
    "\n",
    "for pan_idx, panel_name in enumerate(panels):\n",
    "    image_dfs[panel_name] = pd.DataFrame(columns=[\"image_name\", \"width\", \"height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786fca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the non-deleted files from previous Notebook.\n",
    "\n",
    "islet_imgs = io.list_image_files(folders[\"img\"] / \"Islet\")\n",
    "immune_imgs = io.list_image_files(folders[\"img\"] / \"Immune\")\n",
    "print(f\"is: {len(islet_imgs)}, im: {len(immune_imgs)}\")\n",
    "islet_imgs_names = [x.name.replace(\"_Islet\", \"\").replace(\".tiff\", \"\") for x in islet_imgs]\n",
    "immune_imgs_names = [x.name.replace(\"_Immune\", \"\").replace(\".tiff\", \"\") for x in immune_imgs]\n",
    "display(f\"immune: {sorted(list(set(immune_imgs_names).difference(islet_imgs_names)))}\")\n",
    "display(f\" Islet: {sorted(list(set(islet_imgs_names).difference(immune_imgs_names)))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d58632d3-48e2-4afd-8143-bf6c6e6ba860",
   "metadata": {},
   "source": [
    "### **Generate images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5924acc-a0af-4c11-9113-ab78c7c5439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for panel_name, panel in panels.items():\n",
    "    print(\"Processing\", panel_name, \"panel\")\n",
    "    \n",
    "    # Define channels to use for segmentation\n",
    "    islet_channels = panel[\"isletseg\"].values\n",
    "    islet_channels = np.where(islet_channels == 0, np.nan, islet_channels)\n",
    "    \n",
    "    # Define the input folder\n",
    "    img_subdir = folders[\"img\"] / panel_name\n",
    "    seg_subdir = folders[\"seg_islets\"] / panel_name\n",
    "    seg_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Create and save segmentation images        \n",
    "    for img_path in tqdm(io.list_image_files(img_subdir)):\n",
    "        \n",
    "        segstack_file = seg_subdir / (str(img_path.name))\n",
    "        \n",
    "        if not segstack_file.exists():\n",
    "            islet_img = deepcell.create_segmentation_stack(\n",
    "                img = io.read_image(img_path),\n",
    "                channelwise_minmax = channelwise_minmax,\n",
    "                channelwise_zscore = channelwise_zscore,\n",
    "                channel_groups = islet_channels,\n",
    "                aggr_func = aggr_func\n",
    "            )\n",
    "            io.write_image(islet_img, segstack_file)\n",
    "        else:\n",
    "            islet_img = io.read_image(segstack_file)\n",
    "            \n",
    "        # Add image metadata to the data frame\n",
    "        image_dfs[panel_name] = pd.concat(\n",
    "            [image_dfs[panel_name], pd.DataFrame({\n",
    "                \"image_name\": img_path.stem,\n",
    "                \"width\": islet_img.shape[2],\n",
    "                \"height\": islet_img.shape[1]},\n",
    "                index = [len(image_dfs[panel_name].index)])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80aae9e6-80f7-49b5-8e88-9d5c589c8d44",
   "metadata": {},
   "source": [
    "### **Visual check**\n",
    "Display a few randomly-selected islet segmentation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c6c98-e45e-4c85-8760-74b27feddb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "## number of images per panel to show\n",
    "nb_images_to_show = 5\n",
    "\n",
    "## adjust image max intensity if needed (lower value = higher intensity)\n",
    "max_intensity = 0.25\n",
    "\n",
    "# Randomly select images\n",
    "seg_subdir0 = folders[\"seg_islets\"] / panel_names[0]\n",
    "segstacks = sorted(seg_subdir0.glob(\"*.tiff\"))\n",
    "rng = np.random.default_rng()\n",
    "indexes = rng.choice(len(segstacks), nb_images_to_show, replace=False)\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(nb_images_to_show, 2,\n",
    "                        figsize=(12, 4 * nb_images_to_show))\n",
    "\n",
    "for i,idx in enumerate(indexes):\n",
    "    for j, (panel_name, panel) in enumerate(panels.items()):\n",
    "        \n",
    "        ##load images\n",
    "        seg_subdir = folders[\"seg_islets\"] / panel_name\n",
    "        img_name = segstacks[idx].name.replace(panel_names[0], panel_name)\n",
    "        img = io.read_image(seg_subdir / img_name)\n",
    "    \n",
    "        ## plot images\n",
    "        axs[i,j].imshow(np.squeeze(img), vmin=0, vmax=max_intensity)\n",
    "        axs[i,j].set_title(f\"{img_name}, w:{img.shape[2]}, h:{img.shape[1]}\")\n",
    "        axs[i,j].axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38af5c8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Segment islets**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40852c5d-e45e-42de-96f2-2c60ff524668",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Islet filtering function**\n",
    "\n",
    "Here we define a function that filters islets by size and shape.\n",
    "\n",
    "**Filtering settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbd323-7c3d-49d7-a91e-29bbd25d4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_object_size = 50  ## minimum number of pixels per islet\n",
    "max_eccentricity = 0.95  ## max islet eccentricity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d95fc-212c-4bc5-86be-4f28e242b91f",
   "metadata": {},
   "source": [
    "**Filtering function**  \n",
    "\n",
    "The `filter_islets` function takes the following steps:\n",
    "\n",
    "1. Label individual islets on binary masks.\n",
    "2. Filter islets by size (adjust the `min_object_size` variable below).\n",
    "3. Filter islets by shape: as islet markers are also expressed in blood vessels, elongated objects are removed (adjust the `max_eccentricity` variable below).\n",
    "4. Fill holes in the islet masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58f428-06dc-4f25-b2cf-18396cdc420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_islets(mask, min_obj_size, max_eccent):\n",
    "\n",
    "    # Identify objects and measure their properties\n",
    "    ret, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    labels = measure.label(mask, background=0)\n",
    "    region_props = measure.regionprops(labels)\n",
    "    \n",
    "    # Filter the objects (based on min_object_size and max_eccentricity variables)\n",
    "    labels_to_remove = []\n",
    "    for prop in region_props:\n",
    "        if (prop.area < min_object_size or (\n",
    "            prop.eccentricity > max_eccentricity and prop.area < 5*min_object_size)):\n",
    "            labels_to_remove.append(prop.label)\n",
    "    labels = np.where(np.isin(labels, labels_to_remove), 0, labels)\n",
    "    \n",
    "    # Fill holes\n",
    "    ret, bin_mask = cv2.threshold(labels.astype(\"uint8\"), 0, 255, cv2.THRESH_BINARY)\n",
    "    bin_mask = ndi.binary_fill_holes(bin_mask).astype(bool)\n",
    "    \n",
    "    return bin_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d72d26-a4ba-40d5-9929-d3defb9a9bc3",
   "metadata": {},
   "source": [
    "### **Create the input set**\n",
    "\n",
    "**Complete the image metadata data frame**  \n",
    "\n",
    "This data frame contains all image names, as well as images width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde260d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pan_idx, panel_name in enumerate(panels):\n",
    "    print(pan_idx, panel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420b5f1-5efd-4450-98f4-9abe3b2b1c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "for pan_idx, panel_name in enumerate(panels):\n",
    "    \n",
    "    # List input islet segmentation images\n",
    "    seg_subdir = folders[\"seg_islets\"] / panel_name\n",
    "    input_images = sorted([x.name for x in Path.iterdir(seg_subdir) if x.name.endswith(\".tiff\")])\n",
    "    print(\"Number of images in\", panel_name, \"panel:\", len(input_images))\n",
    "\n",
    "    # Add Case IDs and Panels\n",
    "    image_dfs[panel_name][\"images\"] = image_dfs[panel_name][\"image_name\"] + \".tiff\"\n",
    "    df_meta = image_dfs[panel_name][\"image_name\"].str.split(\"_\", n = 0, expand = True)\n",
    "    image_dfs[panel_name][\"case_id\"] = df_meta[0]\n",
    "    image_dfs[panel_name][\"panel\"] = df_meta[1]\n",
    "    image_dfs[panel_name][\"acq_id\"] = df_meta[3]\n",
    "\n",
    "    # Add paths to images\n",
    "    image_dfs[panel_name][\"dir_images\"] = folders[\"seg_islets\"] / panel_name\n",
    "\n",
    "# Merge the data frames\n",
    "all_image_dfs = pd.concat([df for i,df in image_dfs.items()], ignore_index=True)\n",
    "all_image_dfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0caf6a5b-2784-4783-b27b-2916904d6ff5",
   "metadata": {},
   "source": [
    "**Create the input set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36548b-9a0f-49fd-8acb-1b9775fcd26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 160\n",
    "image_set = helpers.PredictDataset(all_image_dfs, helpers.get_test_augmentations(img_size))\n",
    "assert(len(image_set) == len(all_image_dfs.index)), f\"Data frame and image set have different sizes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f36e5",
   "metadata": {},
   "source": [
    "### **Load the model**\n",
    "\n",
    "Generation of the islet segmentation model is documented in the `islet_segmentation` folder of this repository.  \n",
    "The model can also be directly downloaded from zenodo ***UPDATE: ADD LINK TO THE MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8014f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "islet_model = helpers.IsletModel()\n",
    "# islet_model.load_state_dict(torch.load(folders[\"data\"] / \"islet_segmentation_model.pt\"))\n",
    "islet_model.load_state_dict(torch.load(folders[\"data\"] / \"islet_segmentation\" / \"islet_model.pt\"))\n",
    "islet_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609f2db-f691-45cd-8b12-096139ad97a2",
   "metadata": {},
   "source": [
    "### **Predict and save islet masks**\n",
    "\n",
    "Islet masks are predicted based on the U-NET model, resized to the original image size, and filtered using the `filter_islets` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460e335-c56b-453a-b18f-0ec2c4cc6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(range(len(image_set))):\n",
    "                    \n",
    "    # Predict the mask\n",
    "    image = image_set[idx]\n",
    "    logits_mask = islet_model(image.unsqueeze(0))\n",
    "    mask = torch.sigmoid(logits_mask)\n",
    "    mask = torch.detach(mask)\n",
    "    mask = (mask > 0.5) * 255.0\n",
    "    mask = mask.squeeze().numpy()\n",
    "\n",
    "    # Resize the mask to original image size\n",
    "    dim = (all_image_dfs.loc[idx, \"width\"],\n",
    "           all_image_dfs.loc[idx, \"height\"])\n",
    "    resized_mask = cv2.resize(mask, dim, cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Filter the objects\n",
    "    filtered_mask = filter_islets(resized_mask, min_object_size, max_eccentricity)\n",
    "\n",
    "    # Save the binary mask\n",
    "    mask_file = all_image_dfs.loc[idx, \"image_name\"] + \"_bin.tiff\"\n",
    "    mask_path = folders[\"masks_islets\"] / all_image_dfs.loc[idx, \"panel\"]\n",
    "    mask_path.mkdir(exist_ok=True)\n",
    "    io.write_mask(filtered_mask, mask_path / mask_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c690dd8-1274-43c3-bb4d-78e251e21c93",
   "metadata": {},
   "source": [
    "### **Visual check**\n",
    "Display a few randomly-selected images overlaid with newly-generated islet segmentation masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c0f32a-2e90-494b-b4d1-9103d97aff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images per panel to show\n",
    "nb_images_to_show = 5\n",
    "\n",
    "# Randomly select images\n",
    "seg_masks_dir0 = folders[\"masks_islets\"] / panel_names[0]\n",
    "segmasks = sorted(seg_masks_dir0.glob(\"*.tiff\"))\n",
    "rng = np.random.default_rng()\n",
    "indexes = rng.choice(len(segmasks), nb_images_to_show, replace=False)\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(nb_images_to_show, 2,\n",
    "                        figsize=(12, 4 * nb_images_to_show))\n",
    "\n",
    "for i,idx in enumerate(indexes):\n",
    "    for j, (panel_name, panel) in enumerate(panels.items()):\n",
    "        \n",
    "        ## load images and masks\n",
    "        seg_subdir = folders[\"seg_islets\"] / panel_name\n",
    "        mask_subdir = folders[\"masks_islets\"] / panel_name\n",
    "        img_name = segmasks[idx].name.replace(panel_names[0], panel_name)\n",
    "        img = io.read_image(seg_subdir / img_name.replace(\"_bin.tiff\", \".tiff\"))\n",
    "        mask = io.read_mask(mask_subdir / img_name)\n",
    "        \n",
    "        ## overlay mask borders on images\n",
    "        cur_img = np.squeeze(color.gray2rgb(img*255).astype('uint8'))\n",
    "        borders = mark_boundaries(cur_img, mask*255, mode='thick').astype('uint8')\n",
    "        overlay = cv2.addWeighted(cur_img, 2, borders*255, 0.5, 0)\n",
    "        \n",
    "        ## plot images\n",
    "        axs[i,j].imshow(overlay)\n",
    "        axs[i,j].set_title(f\"{img_name}, h: {mask.shape[0]}, w: {mask.shape[1]}\")\n",
    "        axs[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa4b47-ece7-4347-9f48-1fa5669e37ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Match and relabel islets on consecutive sections**\n",
    "\n",
    "Here, islets on the same image are merged according to their sizes and distances (see the *Islet merging* functions below).  \n",
    "Then, islets from consecutive sections that are positioned at the same place on the consecutive images after optical flow registration are assigned the same label  (see the *Islet relabeling* functions below). Islets which don't have a corresponding islet on the consecutive image are assigned unique labels. With this, it is possible to know in the downstream analysis that islets which have the same label on consecutive images are actually the same islet.\n",
    "\n",
    "This approach works for two panels applied to two consecutive sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376064e-68cb-48b3-ba43-2b15dbde969b",
   "metadata": {},
   "source": [
    "### **Helper functions - Islet merging**\n",
    "\n",
    "These functions are used to merge islets based on their distance and on their relative sizes.\n",
    "\n",
    "Compare to a merge based only on distances, this approach makes a difference between fragmented islets (one large islet with smaller islet cell patches around it) and two islets located next to each other.\n",
    "Here, two large islets will merge less easily than a large islet and a smaller islet cell patch located at the same distance of each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115ff96-6c61-4bd1-bc31-6e4aaf887ae5",
   "metadata": {},
   "source": [
    "**Steps**  \n",
    "\n",
    "The `merge_objects` function merges objects in a binary mask based on their distance and sizes:\n",
    "\n",
    "1. Distances between objects are calculated using the `calculate_distances` function.\n",
    "2. Object areas are measured.\n",
    "3. Merging costs are calculated using the `calculate_merging_cost` function (see details below).\n",
    "4. If the merging cost is higher than the defined `max_cost`, the objects are not merged.\n",
    "5. A minimum spanning tree is calculated from the merging cost matrix and edges (objects to merge) are returned.\n",
    "6. Labeled objects are merged based on calculated edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d60f3b-6883-46a2-90fd-e8124db03fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_objects(binary_mask, weight_dist, weight_area, max_cost):\n",
    "    \n",
    "    # Label the masks\n",
    "    labeled_mask = measure.label(binary_mask)\n",
    "    \n",
    "    # Calculate distances between objects, object areas, and merging cost\n",
    "    distances = calculate_distances(labeled_mask)\n",
    "    object_areas = measure.regionprops_table(labeled_mask, properties = ['area'])['area']\n",
    "    merging_cost = calculate_merging_cost(labeled_mask, distances, object_areas,\n",
    "                                          weight_dist, weight_area)\n",
    "\n",
    "    # display(pd.DataFrame(distances))\n",
    "    # display(pd.DataFrame(object_areas))\n",
    "    \n",
    "    # Calculate minimum spanning tree and return the edges\n",
    "    merging_cost = np.where(merging_cost > max_cost, 0, merging_cost)\n",
    "    # display(pd.DataFrame(merging_cost))\n",
    "    \n",
    "    mst = minimum_spanning_tree(merging_cost)\n",
    "    edges = np.column_stack(mst.nonzero())\n",
    "    edges = np.add(edges, 1)\n",
    "    \n",
    "    # Merge objects based on edges\n",
    "    final_mask = merge_edges(labeled_mask, edges)\n",
    "    \n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6a232-7488-4f9f-a3b7-23f2926e6027",
   "metadata": {},
   "source": [
    "The `calculate_distances` function measures and returns the distances between all object pairs in a labeled mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee257f4e-051f-4a14-a59b-8422b93af36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances between labeled objects\n",
    "def calculate_distances(labeled_mask):\n",
    "    labels = np.unique(labeled_mask)\n",
    "    n_labels = len(labels)\n",
    "    distances = np.zeros((n_labels, n_labels))\n",
    "    \n",
    "    # Calculate distances between each object pairs\n",
    "    for i in range(n_labels):\n",
    "        object_mask = (labeled_mask == labels[i])\n",
    "        distance_map = ndi.distance_transform_edt(~object_mask)\n",
    "        \n",
    "        for j in range(i + 1, n_labels):\n",
    "            other_object_mask = (labeled_mask == labels[j])\n",
    "            distance = np.min(distance_map[other_object_mask])\n",
    "            distances[i,j] = distance\n",
    "            \n",
    "    # Make the matrix symmetric\n",
    "    distances = np.maximum(distances, distances.T)\n",
    "    return distances[1:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35a979-bb01-4cde-8b93-a8e95707c54c",
   "metadata": {},
   "source": [
    "The `calculate_merging_cost` function calculates the merging cost for each object pair of a labeled mask.  \n",
    "\n",
    "The total cost is the sum of the weighted distance cost and the weighted area cost.\n",
    "The weighting values are user-provided : `weight_dist` and `weight_area`, respectively:\n",
    "\n",
    "- `merging cost` = `weight_dist` * `distance_cost` + `weight_area` * `area cost`\n",
    "- `area_cost` = absolute difference between the total area of the two objects and the difference in area between the two objects.\n",
    "- `distance_cost` = distance between the two objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "119c841e-f241-4ce8-be03-bd5d08f5f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_merging_cost(labeled_mask, distances, areas, weight_dist, weight_area):\n",
    "    \n",
    "    labels = np.unique(labeled_mask)\n",
    "    n_labels = len(labels[labels > 0])\n",
    "    merging_cost = np.zeros((n_labels, n_labels))\n",
    "    \n",
    "    # Calculate merging cost between each object pairs\n",
    "    for i in range(n_labels):\n",
    "        for j in range(n_labels):\n",
    "            if (i != j):\n",
    "                area_diff = abs(sqrt(areas[i]) - sqrt(areas[j]))\n",
    "                area_total = sqrt(areas[i]) + sqrt(areas[j])\n",
    "                area_cost = weight_area * abs(area_total - area_diff)\n",
    "                dist_cost = weight_dist * distances[i,j]\n",
    "                merging_cost[i,j] = dist_cost + area_cost\n",
    "                # print(i, j, dist_cost, area_cost)\n",
    "                \n",
    "    # Make the matrix symmetric\n",
    "    merging_cost = np.maximum(merging_cost, merging_cost.T)    \n",
    "    \n",
    "    return merging_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb23d2-c93c-4859-96b9-57e0ff6b0264",
   "metadata": {},
   "source": [
    "The `merge_edges` function merges labeled objects if they share an edge in the minimum spanning tree (connected components).\n",
    "\n",
    "It uses the disjoint-set data structure to keep track of the connected components in the minimum spanning tree. It first initializes the parents and ranks dictionaries for each label. The find function is used to find the representative element of a set and the union function is used to merge the connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13645964-8cc3-4245-ba06-c3da5b613e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_edges(labeled_mask, edges):\n",
    "    labeled_mask = labeled_mask.copy()\n",
    "    labels = np.unique(labeled_mask)\n",
    "    \n",
    "    parents = defaultdict(lambda: None)\n",
    "    ranks = defaultdict(lambda: 0)\n",
    "\n",
    "    def find(x):\n",
    "        if parents[x] != x:\n",
    "            parents[x] = find(parents[x])\n",
    "        return parents[x]\n",
    "\n",
    "    def union(x, y):\n",
    "        px, py = find(x), find(y)\n",
    "        if px != py:\n",
    "            if ranks[px] > ranks[py]:\n",
    "                parents[py] = px\n",
    "            else:\n",
    "                parents[px] = py\n",
    "                if ranks[px] == ranks[py]:\n",
    "                    ranks[py] += 1\n",
    "\n",
    "    for label in labels:\n",
    "        parents[label] = label\n",
    "\n",
    "    for edge in edges:\n",
    "        union(labels[edge[0]], labels[edge[1]])\n",
    "\n",
    "    relabeled_mask = np.zeros_like(labeled_mask)\n",
    "    for label in labels:\n",
    "        relabeled_mask[labeled_mask == label] = find(label)    \n",
    "    \n",
    "    return relabeled_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b7f2c-4ce3-4c4a-903c-b03acfc6a59f",
   "metadata": {},
   "source": [
    "### **Helper functions - Islet relabeling**\n",
    "\n",
    "These functions are used to measure the overlap between all object pairs in two consecutive images, and to assign the same labels to overlapping objects.  \n",
    "\n",
    "The `get_regionprops_overlap` function takes two labeled masks from consecutive images as input and returns a mapping table (`regprops`) containing the overlap between all pair of objects (with one object on the first image and the other object on the consecutive image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "299d7543-0685-4d14-bd15-467e705bf0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regionprops_overlap(labels_panel1, labels_panel2):\n",
    "    \n",
    "    region_props = pd.DataFrame()\n",
    "    \n",
    "    for i in range(1, np.max(labels_panel1)+1):\n",
    "        cur_object = np.where(labels_panel1==i, 1, 0)\n",
    "        cur_props = pd.DataFrame(measure.regionprops_table(\n",
    "            labels_panel2, cur_object, properties = ['intensity_mean']))\n",
    "        \n",
    "        cur_props.rename(columns = {'intensity_mean': i}, inplace = True)\n",
    "        cur_props.set_axis(np.unique(labels_panel2[labels_panel2>0]), inplace=True)\n",
    "        region_props = pd.concat([region_props, cur_props], axis=1)        \n",
    "    \n",
    "    return region_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e36cf3f-1f37-45d0-828b-d7bf169d0a58",
   "metadata": {},
   "source": [
    "The `relabel_masks` function takes a labeled mask and a mapping table (`regprops`) of overlapping objects.  \n",
    "- If the table indicates that labeled object ***c*** in the labeled mask overlaps with object ***n*** in the consecutive image, and if the overlap is greater than the user-defined threshold (see `overlap_thresh` in parameters below), then object ***c*** is relabeled as ***n***.\n",
    "- If another object ***d*** does not overlap with any other object in the consecutive image, it receives a unique label ***y*** (defined by the `nonoverlap_lab` variable) that is larger than all existing labels in the mapping table.  \n",
    "  \n",
    "Finally, the function returns the relabeled mask, the mapping between old and new labels (here, *{c: n, d: y}*), and the incremented `nonoverlap_lab` value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c41e8da4-fb1c-40ec-9d75-0eaed0d9ea69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def relabel_masks(mask_labeled, regprops, threshold, nonoverlap_lab) :\n",
    "    \n",
    "    old_new = dict()\n",
    "    mask_relabeled = mask_labeled.copy()\n",
    "    reg_indexes = regprops.index\n",
    "    \n",
    "    for i in reg_indexes:\n",
    "        new_id = np.min(regprops.loc[i][regprops.loc[i] >= threshold].index)\n",
    "        \n",
    "        if(not np.isnan(new_id)):\n",
    "            mask_relabeled[mask_labeled==i] = new_id\n",
    "            old_new.update({i: new_id})\n",
    "        else:\n",
    "            mask_relabeled[mask_labeled==i] = nonoverlap_lab\n",
    "            old_new.update({i: nonoverlap_lab})\n",
    "            nonoverlap_lab += 1\n",
    "            \n",
    "    return mask_relabeled, old_new, nonoverlap_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9091a45e-83f8-487a-b56f-c7433126e60a",
   "metadata": {},
   "source": [
    "The `pad_images` function takes two images as input. It calculates which image has the larger width and which image has the larger height. It then pads the image with the smaller width and the image with the smaller height with a uniform color defined by the `pad_color` variable. Finally, it returns the two padded images, which have the same size, and the offset coordinates, which can later be used to crop-out the paddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "750b1217-ed05-43fd-a671-89fcd8a920bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_images(image1, image2, pad_color):\n",
    "\n",
    "    # Image shapes\n",
    "    y1, x1 = np.squeeze(image1).shape\n",
    "    y2, x2 = np.squeeze(image2).shape\n",
    "    \n",
    "    max_width = np.maximum(x1, x2)\n",
    "    max_height = np.maximum(y1, y2)\n",
    "\n",
    "    # Compute offsets between image centers\n",
    "    offset_x1 = max((x2 - x1) // 2, 0)\n",
    "    offset_y1 = max((y2 - y1) // 2, 0)\n",
    "    offset_x2 = max((x1 - x2) // 2, 0)\n",
    "    offset_y2 = max((y1 - y2) // 2, 0)\n",
    "\n",
    "    # Create empty padded images\n",
    "    image1_padded = np.full((max_height, max_width), pad_color, dtype=np.uint8)\n",
    "    image2_padded = np.full((max_height, max_width), pad_color, dtype=np.uint8)\n",
    "\n",
    "    # Copy original images into the center of the padded images\n",
    "    image1_padded[offset_y1 : offset_y1 + y1,\n",
    "                  offset_x1 : offset_x1 + x1] = image1.copy()\n",
    "                                                                         \n",
    "    image2_padded[offset_y2 : offset_y2 + y2,\n",
    "                  offset_x2 : offset_x2 + x2] = image2.copy()\n",
    "    \n",
    "    # Make tupple with offset coordinates to return\n",
    "    img1_offset_coord = (offset_y1, offset_y1+y1, offset_x1, offset_x1+x1)\n",
    "    img2_offset_coord = (offset_y2, offset_y2+y2, offset_x2, offset_x2+x2)\n",
    "    \n",
    "    return image1_padded, image2_padded, img1_offset_coord, img2_offset_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd8f8f-4cd6-45cd-a3d7-4a1aa2612087",
   "metadata": {},
   "source": [
    "### **Process images and masks**\n",
    "\n",
    "Here, the functions defined above are used to match islets on consecutive sections and relabel them accordingly.\n",
    "\n",
    "**Steps** (for details, see descriptions of the functions above)\n",
    "\n",
    "1. Load images and masks from two consecutive sections stained with panel1 and panel2.\n",
    "2. Label the masks `mask1_init_labels` and `mask2_init_labels`.\n",
    "3. Pad the smaller image and mask, so that all images and masks have the same size, using the `pad_images` function.\n",
    "4. Apply optical flow on the first image, to make it similar to the second image.\n",
    "5. Apply the optical flow transformation to the first mask (`mask1_corrected`).\n",
    "6. Threshold the masks and filter them using the `filter_islets` function, as already done after islet segmentation.\n",
    "7. Merge the islets based on their distance and sizes (see the *Helper functions - Islet merging* paragraph above).\n",
    "The user can define the distance and area weights in the parameters below, as well as the maximum cost allowed for merging two objects.\n",
    "8. Calculate the overlap between the mask1 objects (after optical flow transformation) and the mask2 objects.\n",
    "If the overlap is greater than the user defined `overlap_thresh`, the mask1 objects as relabeled as in mask2.\n",
    "9. Calculate the overlap between the mask2 objects and the relabeled mask1 objects. Relabel the overlapping objects from mask2 as in `mask1_relabeled`.\n",
    "10. Relabel the initial masks `mask1_init_labels` and `mask2_init_labels`, according to the relabeled masks `mask1_relabeled` and `mask2_relabeled`.\n",
    "\n",
    "\n",
    "**User-defined parameters**\n",
    "\n",
    "- `distance_weight`: When calculating the merging cost, multiplier applied to the distance between the objects.\n",
    "- `area_weight`:  When calculating the merging cost, multiplier applied to the area cost (see the `calculate_merging_cost` function above for details).\n",
    "- `max_cost`: Maximal merging cost, above which two objects are not merged.\n",
    "- `overlap_thresh`: Fraction of overlap above which two objects from consecutive sections are considered as overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4227b84b-142c-4612-bfd9-3183b6cc40f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Islet merging parameters (on the same image)\n",
    "distance_weight = 3\n",
    "area_weight = 1.25\n",
    "max_cost = 250\n",
    "\n",
    "# Islet alignment parameters (on consecutive images)\n",
    "overlap_thresh = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94271cf7-a096-45bf-9cb2-833f373fcb55",
   "metadata": {},
   "source": [
    "**Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6885f7-e029-4a9c-aa74-a041b426dca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input folders\n",
    "img1_subdir = folders[\"seg_islets\"] / panel_names[0]\n",
    "img2_subdir = folders[\"seg_islets\"] / panel_names[1]\n",
    "masks1_subdir = folders[\"masks_islets\"] / panel_names[0]\n",
    "masks2_subdir = folders[\"masks_islets\"] / panel_names[1]\n",
    "\n",
    "temp_masks_panel1 = list(m for m in io.list_image_files(masks1_subdir) if \"_bin\" in str(m))\n",
    "\n",
    "for file in tqdm(temp_masks_panel1):\n",
    "\n",
    "    file1 = file.name\n",
    "    file2 = file.name.replace(panel_names[0], panel_names[1])\n",
    "    out_mask_name1 = masks1_subdir / file1.replace(\"_bin\", \"\")\n",
    "    out_mask_name2 = masks2_subdir / file2.replace(\"_bin\", \"\")\n",
    "    \n",
    "    if(not(Path.exists(out_mask_name1) and Path.exists(out_mask_name2))):\n",
    "\n",
    "        # Read masks and assign initial labels\n",
    "        mask1 = cv2.imread(str(masks1_subdir / file1), cv2.IMREAD_UNCHANGED)\n",
    "        mask2 = cv2.imread(str(masks2_subdir / file2), cv2.IMREAD_UNCHANGED)\n",
    "        mask1_init_labels = measure.label(mask1)\n",
    "        mask2_init_labels = measure.label(mask2)\n",
    "\n",
    "        if (np.amax(mask1_init_labels) > 1) or (\n",
    "            np.amax(mask2_init_labels) > 1):\n",
    "\n",
    "            # Read images and convert them to 8-bit\n",
    "            img1 = cv2.imread(str(img1_subdir / file1.replace(\"_bin\", \"\")), cv2.IMREAD_UNCHANGED)\n",
    "            img2 = cv2.imread(str(img2_subdir / file2.replace(\"_bin\", \"\")), cv2.IMREAD_UNCHANGED)\n",
    "            img1 = (img1 * 255).astype('uint8')\n",
    "            img2 = (img2 * 255).astype('uint8')\n",
    "\n",
    "            # Pad the smaller image and mask, to make sure both images/masks have the same size\n",
    "            img1_padded, img2_padded, img1_off, img2_off = pad_images(img1, img2, (0))\n",
    "            mask1_padded, mask2_padded, mask1_off, mask2_off = pad_images(\n",
    "                mask1_init_labels, mask2_init_labels, (0)\n",
    "            )\n",
    "\n",
    "            # Learn optical flow registration based on images\n",
    "            v, u = optical_flow_tvl1(img1_padded, img2_padded, attachment=50, num_warp=50)\n",
    "\n",
    "            row_coords, col_coords = np.meshgrid(np.arange(img2_padded.shape[0]),\n",
    "                                                 np.arange(img2_padded.shape[1]),\n",
    "                                                 indexing = 'ij')\n",
    "\n",
    "            # Apply learnt registration to the first panel mask\n",
    "            dest_mat = np.array([row_coords - v, col_coords - u])\n",
    "            mask1_corrected = (warp(mask1_padded, dest_mat, mode='edge') * 255).astype('uint8')\n",
    "\n",
    "            # Filter and merge the corrected masks\n",
    "            ret, mask1_thresh = cv2.threshold(mask1_corrected, 0, 255, cv2.THRESH_BINARY)\n",
    "            ret, mask2_thresh = cv2.threshold(mask2_padded, 0, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            mask1_filtered = filter_islets(mask1_thresh, min_object_size, max_eccentricity)\n",
    "            mask2_filtered = filter_islets(mask2_thresh, min_object_size, max_eccentricity)\n",
    "            \n",
    "            mask1_labels = merge_objects(mask1_filtered, distance_weight, area_weight, max_cost)\n",
    "            mask2_labels = merge_objects(mask2_filtered, distance_weight, area_weight, max_cost)\n",
    "\n",
    "            if (np.amax(mask1_labels) > 0) and (np.amax(mask2_labels) > 0):\n",
    "                \n",
    "                # Match islets from consecutive sections (based on overlap) and relabel first panel mask\n",
    "                region_props1 = get_regionprops_overlap(mask2_labels, mask1_labels)\n",
    "                cur_unmatched_label = int(np.max([np.max(region_props1.index),\n",
    "                                                  np.max(region_props1.columns)])) + 1\n",
    "                mask1_relabeled, new_labels1, cur_unmatched_label = relabel_masks(\n",
    "                    mask1_labels, region_props1, overlap_thresh, cur_unmatched_label\n",
    "                )\n",
    "\n",
    "                # Match islets from consecutive sections and relabel second panel mask\n",
    "                region_props2 = get_regionprops_overlap(mask1_relabeled, mask2_labels)\n",
    "                mask2_relabeled, new_labels2, cur_unmatched_label = relabel_masks(\n",
    "                    mask2_labels, region_props2, overlap_thresh, cur_unmatched_label\n",
    "                )\n",
    "\n",
    "                # Re-label initial mask1 with the new labels that match the second panel labels\n",
    "                region_props_final1 = get_regionprops_overlap(mask1_relabeled, mask1_corrected)\n",
    "                mask1_final, new_labels_final1, cur_unmatched_label = relabel_masks(\n",
    "                    mask1_init_labels, region_props_final1, overlap_thresh, cur_unmatched_label\n",
    "                )\n",
    "\n",
    "                # Re-label initial mask2 with the new labels that match the first panel labels\n",
    "                region_props_final2 = get_regionprops_overlap(mask2_relabeled, mask2_padded)\n",
    "                mask2_final, new_labels_final2, cur_unmatched_label = relabel_masks(\n",
    "                    mask2_init_labels, region_props_final2, overlap_thresh, cur_unmatched_label\n",
    "                )\n",
    "            else:\n",
    "                mask1_final = mask1_labels.copy()\n",
    "                mask2_final = mask2_labels.copy()\n",
    "\n",
    "        else:\n",
    "            mask1_final = mask1.copy()\n",
    "            mask2_final = mask2.copy()\n",
    "\n",
    "        # Save re-labeled masks and remove temporary masks\n",
    "        io.write_mask(mask1_final, out_mask_name1)\n",
    "        io.write_mask(mask2_final, out_mask_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c797c-6d44-4387-aa9c-7ee445ca1e28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Quality check**\n",
    "\n",
    "Acquisition and islet masks from consecutive sections (panels) are displayed side-by-side to visually confirm that:\n",
    "1. Matched images actually correspond to the same region.\n",
    "2. When the same islet is found on consecutive sections, it has the same labels.\n",
    "\n",
    "All images in the dataset were checked for quality and problematic images (e.g., bad quality, failed islet segmentation) were manually flagged for deletion.\n",
    "\n",
    "### **Settings**\n",
    "\n",
    "The following variables can be adjusted:\n",
    "- Select from which donor (4 digits case id) images should be displayed.\n",
    "- Select the number of images to show (random subset).\n",
    "- Select the max intensity for image display.\n",
    "- Select the mask overlay transparency.\n",
    "- In addition, a color palette is generated for mapping mask values to specific colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a78df926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only images from the following patient (4-digits case id)\n",
    "# if `None`, images from all patients will be displayed\n",
    "case_id = None \n",
    "\n",
    "# Select the number of images to show\n",
    "# if `None`, all the images will be displayed\n",
    "nb_img_to_show = 50\n",
    "\n",
    "# Adjust image max intensity if needed (lower value = higher intensity)\n",
    "max_intensity = 0.5\n",
    "\n",
    "# Adjust mask transparency\n",
    "overlay_alpha = 0.33\n",
    "\n",
    "# Color palette\n",
    "cmap = plt.cm.tab20\n",
    "cmaplist = (np.array([cmap(i) for i in range(cmap.N)]) * 255).astype('uint8')\n",
    "cmaplist = np.delete(cmaplist, 3, 1)\n",
    "cmaplist = np.vstack([[0,  0,  0], cmaplist, cmaplist])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e6ad9-ad90-4646-8039-5bc788a57088",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Display images and masks**\n",
    "\n",
    "**Select images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d16b9a39-4acb-4bef-806b-de13e25b4e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 images will be displayed\n"
     ]
    }
   ],
   "source": [
    "# List all the masks for the first panel\n",
    "panel1_islet_masks_dir = folders['masks_islets'] / panel_names[0]\n",
    "img_to_show = [mask for mask in io.list_mask_files(\n",
    "    panel1_islet_masks_dir) if not mask.name.endswith(\"_bin.tiff\")]\n",
    "\n",
    "# If a specific case is selected, subset the images from this case\n",
    "if case_id is not None:\n",
    "    img_to_show = [mask for mask in img_to_show if mask.name.startswith(str(case_id))]\n",
    "\n",
    "# If a number of `nb_img_to_show` is not `None`, randomly subset that number of images\n",
    "if nb_img_to_show is not None:\n",
    "    rng = np.random.default_rng()\n",
    "    idx = rng.choice(len(img_to_show),\n",
    "                     np.minimum(nb_img_to_show, len(img_to_show)), replace = False)\n",
    "    img_to_show = [img_to_show[i] for i in idx]\n",
    "    \n",
    "# Count and display the final number of images to display\n",
    "nb_img_to_show = len(img_to_show)\n",
    "print(str(nb_img_to_show) + \" images will be displayed\")\n",
    "\n",
    "if (nb_img_to_show > 50):\n",
    "    print(\"WARNING - More than 50 images are selected for display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d9a08-9a28-4ded-9d44-204428bfa10c",
   "metadata": {},
   "source": [
    "**Display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb73fb-ed83-4d63-9502-b0f6e3a5f6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nb_img_to_show, 2 * len(panel_names),\n",
    "                       figsize=(18, 5 * nb_img_to_show))\n",
    "\n",
    "for i, file in enumerate(sorted(img_to_show)):\n",
    "    for pan_idx, panel_name in enumerate(panel_names):\n",
    "        \n",
    "        # Load masks and images\n",
    "        file_name = file.name.replace(panel_names[0], panel_names[pan_idx])\n",
    "        cur_masks_dir = folders['masks_islets'] / panel_name\n",
    "        cur_img_dir = folders['seg_islets'] / panel_name\n",
    "        \n",
    "        img = io.read_image(cur_img_dir / file_name)\n",
    "        mask = io.read_mask(cur_masks_dir / file_name)\n",
    "        \n",
    "        # Check for even sizes.\n",
    "        if img.shape[1:3] != mask.shape:\n",
    "            warnings.warn(f\"Unequal Shapes; skip this image {file_name}and delete later.\")\n",
    "            display(img.shape, mask.shape)\n",
    "            break\n",
    "\n",
    "        # Normalize image and convert to grayscale\n",
    "        cur_img = exposure.adjust_sigmoid(img[0,...], 0.1)\n",
    "        cur_img = color.gray2rgb(cur_img*255).astype('uint8')\n",
    "        \n",
    "        # Color objects according to the map defined above, identify borders\n",
    "        cur_mask = cmaplist[mask].astype('uint8')\n",
    "        borders = mark_boundaries(cur_img, mask, mode='thick').astype('uint8')\n",
    "        \n",
    "        # Create a overlay with images, colored masks and borders\n",
    "        overlay = cv2.addWeighted(cur_img, (1-overlay_alpha),\n",
    "                                  cur_mask, overlay_alpha, 0)\n",
    "        overlay = cv2.addWeighted(overlay, 1, borders*255, 0.5, 0)\n",
    "        \n",
    "        # Display images and overlays\n",
    "        ax[i,pan_idx].imshow(img[0,:,:], vmax = max_intensity)\n",
    "        ax[i,pan_idx].set_title(file_name)\n",
    "        ax[i,pan_idx].axis('off')\n",
    "        \n",
    "        ax[i,pan_idx+2].imshow(overlay, vmax = 1)\n",
    "        ax[i,pan_idx+2].axis('off')\n",
    "\n",
    "plt.savefig(folders[\"data\"] / \"example_inferred_islets.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da547990-3fc4-4f40-8639-d150f75bed88",
   "metadata": {},
   "source": [
    "### **Flag and delete problematic images**\n",
    "\n",
    "All images are visually checked and problematic images are flagged for deletion. The reason for which an image was flagged is indicated (`#0`), with numbers corresponding to the following code:\n",
    "- **#1**: Bad image quality: no visible signal, or clear acquisition artifacts.\n",
    "- **#2**: Mismatched regions: two different regions have been acquired on the consecutive sections.\n",
    "- **#3**: Broken acquisition: software crash or other problems during acquisition that make the images unusable.\n",
    "- **#4**: Islet segmentation issue: islet not segmented or segmented region does not correspond to an islet.\n",
    "- **#5**: Cell segmentation issue: these images cause issues with cell segmentation (script 03), for unknown reasons.\n",
    "- Slide 6181 (Immune panel) partially dried out during immunostaining. Images in the corresponding region are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be3ebf-37df-4f84-b700-1d64c65c7cbd",
   "metadata": {},
   "source": [
    "**Manually flag images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5213a33-e1c0-406c-9829-b85aacd0224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_images = {\n",
    "    \"6034\": [\"073\"], #1\n",
    "    \"6043\": [\"015\", \"018\", \"029\", \"031\", \"033\", \"054\", \"056\", \"060\", \\\n",
    "             \"062\", \"063\", \"067\", \"071\", \"073\"], # #2 = 033, 060; #5 = 056; # See note above.\n",
    "    \"6048\": [\"075\"], #2\n",
    "    \"6061\": [\"010\", \"016\"], #2, #4\n",
    "    \"6063\": [\"006\", \"018\", \"019\", \"020\", \"022\", \"025\", \"037\", \\\n",
    "             \"041\", \"052\", \"053\", \"056\", \"060\", \"061\", \"064\", \\\n",
    "             \"066\", \"068\", \"069\"], #2 (1-7), #4, #2 (9-16), #1\n",
    "    \"6090\": [\"051\", \"061\"], #1\n",
    "    \"6135\": [\"063\", \"075\"], #1\n",
    "    \"6143\": [\"025\", \"043\"], #1\n",
    "    \"6150\": [\"006\", \"046\"], #2, #1\n",
    "    \"6171\": [\"031\", \"066\", \"083\", \"084\"], #3, #1, #2, #2\n",
    "    \"6181\": [\"009\", \"011\", \"013\", \"014\", \"017\", \"019\",\\\n",
    "             \"020\", \"021\", \"022\", \"028\", \"036\", \"037\",\\\n",
    "             \"045\", \"049\", \"050\", \"052\", \"053\", \"062\",\\\n",
    "             \"065\", \"066\", \"067\", \"074\", \"080\"], #see note above\n",
    "    \"6197\": [\"068\", \"077\", \"087\"], #1\n",
    "    \"6208\": [\"011\", \"013\"], #1\n",
    "    \"6209\": [\"021\", \"032\", \"038\", \"064\"], #1, #3, #3, #2\n",
    "    \"6224\": [\"002\"], #1\n",
    "    \"6228\": [\"027\",\"031\",\"035\",\"040\",\"050\",\"055\",\"075\"], #1\n",
    "    \"6229\": [\"041\"], #5\n",
    "    \"6234\": [\"045\", \"081\"], #3, #2\n",
    "    \"6247\": [\"001\", \"003\", \"007\", \"013\", \"016\", \"024\", \"040\", \\\n",
    "             \"047\", \"050\", \"051\", \"056\", \"060\", \"061\", \"066\"], #2\n",
    "    \"6264\": [\"002\", \"061\"], #4, #1\n",
    "    \"6289\": [\"075\"], #2\n",
    "    \"6301\": [\"063\", \"079\"], #1, #2\n",
    "    \"6303\": [\"017\", \"036\", \"072\"], #2\n",
    "    \"6310\": [\"007\", \"062\"], #2\n",
    "    \"6314\": [\"007\"], #2 \n",
    "    \"6324\": [\"018\", \"021\", \"033\", \"061\"], #1\n",
    "    \"6362\": [\"003\", \"005\", \"006\", \"007\", \"008\", \"011\", \"014\", \"041\", \"043\", \"050\", \"051\", \"066\"], #2\n",
    "    \"6388\": [\"002\", \"003\", \"036\", \"045\", \"048\", \"048\", \"051\", \"054\", \"058\", \"060\", \"062\", \"063\", \"074\"], #2\n",
    "    \"6396\": [\"025\"], #5\n",
    "    \"6397\": [\"071\"], #1\n",
    "    \"6405\": [\"077\"], #2\n",
    "    \"6414\": [\"075\"], #2\n",
    "    \"6418\": [\"032\"], #1\n",
    "    \"6422\": [\"006\", \"016\"], #4, #4\n",
    "    \"6428\": [\"010\", \"020\", \"029\", \"033\", \"048\"],  #2, #3, #2, #2, #2\n",
    "    \"6433\": [\"002\"], #1\n",
    "    \"6437\": [\"019\"], #2\n",
    "    \"6450\": [\"011\", \"020\", \"055\"], #1\n",
    "    \"6456\": [\"079\"], #2\n",
    "    \"6458\": [\"039\", \"078\"],\n",
    "    \"6483\": [\"025\"], #2\n",
    "    \"6494\": [\"005\", \"011\", \"016\", \"030\", \"060\", \"073\"], #2\n",
    "    \"6449\": [\"067\"],  #2\n",
    "    \"6506\": [\"006\", \"022\", \"027\", \"028\", \"029\", \"070\"], #2, #1 #2 #4 #4, #1\n",
    "    \"6509\": [\"016\"], #4\n",
    "    \"6510\": [\"060\", \"064\"], #1\n",
    "    \"6512\": [\"022\", \"053\"], #2\n",
    "    \"6514\": [\"044\"], #2\n",
    "    \"6517\": [\"008\", \"038\", \"048\", \"061\", \"073\"], #1, #1, #5, #1, #4\n",
    "    \"6520\": [\"059\"], #4\n",
    "    \"6538\": [\"087\"], #4\n",
    "    \"6547\": [\"042\"], #2\n",
    "    \"6549\": [\"035\"], #4\n",
    "    \"6550\": [\"028\", \"077\"], #4, #2\n",
    "    \"6551\": [\"023\", \"029\", \"048\", \"072\"], #4, #2, #2, #2\n",
    "    \"6563\": [\"054\"], #4   \n",
    "    \"8011\": [\"011\", \"054\", \"075\"] #2\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80fb9045-2918-41be-96ee-b5688abcae0b",
   "metadata": {},
   "source": [
    "**Delete flagged images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30ac6e-38df-4ab9-9829-022d6d756206",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_flagged_images = True\n",
    "\n",
    "# Make a list of flagged images\n",
    "flagged_img_list = list(chain.from_iterable(map(lambda x: [x[0] + \"__\" + str(i) for i in x[1]], flagged_images.items())))\n",
    "\n",
    "# Directories from which the images should be deleted\n",
    "target_directories = [folders[\"img\"], folders[\"seg_islets\"], folders[\"masks_islets\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2343ae-6784-4920-9145-6da8875e67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flagged_img_list and delete_flagged_images:\n",
    "    for panel_name in panel_names:\n",
    "        for directory in target_directories:\n",
    "            cur_dir = directory / panel_name\n",
    "            images_to_delete = [\n",
    "                cur_dir / (im.replace(\"__\", (\"_\" + panel_name + \"_ROI_\")) + \".tiff\") \\\n",
    "                for im in flagged_img_list]\n",
    "            \n",
    "            for image in images_to_delete:\n",
    "                Path.unlink(image, missing_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bf9f66c",
   "metadata": {},
   "source": [
    "**Remove binary masks**\n",
    "\n",
    "These masks are generated during an intermediate step of the islet segmentation process and are not needed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4ce3a-62c7-4e1f-a5b6-c2dd81a88558",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_masks = [mask for mask in io.list_mask_files(folders[\"masks_islets\"]) if mask.name.endswith(\"_bin.tiff\")]\n",
    "\n",
    "for bin_mask in bin_masks:\n",
    "    Path.unlink(bin_mask, missing_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8cf08b3",
   "metadata": {},
   "source": [
    "## **Next step**\n",
    "\n",
    "The next step in this pipeline is cell segmentation, which is performed with the `03_CellSegmentation.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4af3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
